"""
F4: æ”¹å–„æ¡ˆã‚’ç”Ÿæˆ
PydanticOutputParser + Mustå„ªå…ˆã‚®ãƒ£ãƒƒãƒ—çµã‚Šè¾¼ã¿
"""
import os
from typing import List, Optional, Dict
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_core.output_parsers import PydanticOutputParser
from langchain_core.prompts import PromptTemplate

from models import (
    Requirement,
    RequirementWithEvidence,
    Gap,
    Improvements,
    ResumeEdit,
    ActionItem,
    F4Output,
    RequirementType
)

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()


def generate_improvements(
    job_text: str,
    resume_text: str,
    requirements: List[Requirement],
    matched: List[RequirementWithEvidence],
    gaps: List[Gap],
    options: Optional[dict] = None
) -> Improvements:
    """
    ã‚®ãƒ£ãƒƒãƒ—åˆ†æã‹ã‚‰æ”¹å–„æ¡ˆã‚’ç”Ÿæˆã™ã‚‹ï¼ˆF4ï¼‰

    Args:
        job_text: æ±‚äººç¥¨ã®ãƒ†ã‚­ã‚¹ãƒˆ
        resume_text: è·å‹™çµŒæ­´æ›¸ã®ãƒ†ã‚­ã‚¹ãƒˆ
        requirements: å…¨è¦ä»¶ãƒªã‚¹ãƒˆ
        matched: ãƒãƒƒãƒã—ãŸè¦ä»¶ã¨æ ¹æ‹ ã®ãƒšã‚¢
        gaps: ã‚®ãƒ£ãƒƒãƒ—ã®ã‚ã‚‹è¦ä»¶
        options: ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¾æ›¸
            - llm_provider: "openai" or "anthropic"ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ "openai"ï¼‰
            - model_name: ãƒ¢ãƒ‡ãƒ«å
            - max_gaps: æœ€å¤§ã‚®ãƒ£ãƒƒãƒ—ä»¶æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ5ï¼‰

    Returns:
        Improvements: æ”¹å–„æ¡ˆ
    """
    # ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    if options is None:
        options = {}

    llm_provider = options.get("llm_provider", "openai")
    model_name = options.get("model_name", None)
    max_gaps = options.get("max_gaps", 5)

    # ã‚®ãƒ£ãƒƒãƒ—ã‚’Mustå„ªå…ˆã§ã‚½ãƒ¼ãƒˆã€ä¸Šä½Nä»¶ã‚’é¸æŠ
    sorted_gaps = _prioritize_gaps(gaps, max_count=max_gaps)

    # LLMã®åˆæœŸåŒ–
    try:
        if llm_provider == "anthropic":
            llm = ChatAnthropic(
                model=model_name or "claude-3-5-sonnet-20241022",
                temperature=0.2,  # å°‘ã—å‰µé€ æ€§ã‚’æŒãŸã›ã‚‹
                api_key=os.getenv("ANTHROPIC_API_KEY")
            )
        else:  # openai
            llm = ChatOpenAI(
                model=model_name or "gpt-4o-mini",
                temperature=0.2,
                api_key=os.getenv("OPENAI_API_KEY")
            )

        # ãƒ‘ãƒ¼ã‚µãƒ¼è¨­å®š
        parser = PydanticOutputParser(pydantic_object=F4Output)

        # ã‚®ãƒ£ãƒƒãƒ—æƒ…å ±ã‚’æ–‡å­—åˆ—åŒ–
        gaps_str = "\n".join([
            f"[{g.requirement.req_id}] {g.requirement.category.value}: {g.requirement.description}\n  ç†ç”±: {g.evidence.reason}"
            for g in sorted_gaps
        ])

        # ãƒãƒƒãƒæƒ…å ±ã‚’æ–‡å­—åˆ—åŒ–ï¼ˆå‚è€ƒæƒ…å ±ï¼‰
        matched_str = "\n".join([
            f"[{m.requirement.req_id}] {m.requirement.description}"
            for m in matched[:3]  # æœ€å¤§3ä»¶
        ])

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
        prompt_template = PromptTemplate(
            template="""ã‚ãªãŸã¯ã‚­ãƒ£ãƒªã‚¢ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚ä»¥ä¸‹ã®æƒ…å ±ã‚’ã‚‚ã¨ã«ã€æ±‚è·è€…ãŒæ±‚äººç¥¨ã®è¦ä»¶ã‚’æº€ãŸã™ãŸã‚ã®æ”¹å–„æ¡ˆã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚

æ±‚äººç¥¨ï¼ˆæŠœç²‹ï¼‰ï¼š
{job_text}

è·å‹™çµŒæ­´æ›¸ï¼ˆæŠœç²‹ï¼‰ï¼š
{resume_text}

ç¾åœ¨ãƒãƒƒãƒã—ã¦ã„ã‚‹è¦ä»¶ï¼ˆå‚è€ƒï¼‰ï¼š
{matched_str}

ã‚®ãƒ£ãƒƒãƒ—ã®ã‚ã‚‹è¦ä»¶ï¼ˆæ”¹å–„å¯¾è±¡ï¼‰ï¼š
{gaps_str}

æ”¹å–„æ¡ˆä½œæˆãƒ«ãƒ¼ãƒ«ï¼š

1. **resume_editsï¼ˆè·å‹™çµŒæ­´æ›¸ã®ç·¨é›†ãƒ»è¿½è¨˜æ¡ˆï¼‰**
   - æ—¢ã«æŒã£ã¦ã„ã‚‹çµŒé¨“ãƒ»ã‚¹ã‚­ãƒ«ã‚’å¼·èª¿ã™ã‚‹å ´åˆï¼šedit_type="emphasize"
   - æ–°ãŸã«è¿½è¨˜ã™ã¹ãå†…å®¹ãŒã‚ã‚‹å ´åˆï¼šedit_type="add"
   - æ›¸ãæ›ãˆãŒå¿…è¦ãªå ´åˆï¼šedit_type="rewrite"
   - templateã«ã¯ã€Œä½•ã‚’æ›¸ãã¹ãã‹ã€ã®é …ç›®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
   - exampleã«ã¯å…·ä½“çš„ãªè¨˜è¿°ä¾‹ã‚’æç¤º

2. **action_itemsï¼ˆè¡Œå‹•è¨ˆç”»ï¼‰**
   - Mustè¦ä»¶ã®ä¸è¶³ã¯å„ªå…ˆåº¦Aï¼ˆæœ€å„ªå…ˆãƒ»çŸ­æœŸï¼‰
   - Wantè¦ä»¶ã®ä¸è¶³ã¯å„ªå…ˆåº¦Bï¼ˆä¸­æœŸï¼‰ã¾ãŸã¯Cï¼ˆé•·æœŸï¼‰
   - å­¦ç¿’ã€è³‡æ ¼å–å¾—ã€å®Ÿç¸¾ä½œã‚Šãªã©å…·ä½“çš„ãªè¡Œå‹•ã‚’ææ¡ˆ
   - estimated_impactã¯åŠ¹æœã®é«˜ã•ï¼ˆHigh/Medium/Lowï¼‰

3. **overall_strategyï¼ˆå…¨ä½“æˆ¦ç•¥ï¼‰**
   - æ”¹å–„ã®æ–¹å‘æ€§ã‚’1ã€œ2æ–‡ã§è¦ç´„
   - ã€Œã¾ãšã€œã€æ¬¡ã«ã€œã€ã®ã‚ˆã†ãªå„ªå…ˆé †ä½ã‚’ç¤ºã™

**é‡è¦**: çµŒé¨“ãŒãªã„ã‚‚ã®ã¯æé€ ã›ãšã€ã€Œå­¦ç¿’ã€ã€Œå®Ÿç¸¾ä½œã‚Šã€ãªã©ã®ç¾å®Ÿçš„ãªè¡Œå‹•è¨ˆç”»ã‚’ææ¡ˆã™ã‚‹ã“ã¨ã€‚

{format_instructions}
""",
            input_variables=["job_text", "resume_text", "matched_str", "gaps_str"],
            partial_variables={"format_instructions": parser.get_format_instructions()}
        )

        # job/resumeã‚’å¿…è¦æœ€å°é™ã«ã‚«ãƒƒãƒˆï¼ˆé•·æ–‡ã§å£Šã‚Œã‚„ã™ã„å ´åˆï¼‰
        job_text_trimmed = _trim_job_text(job_text, sorted_gaps)
        resume_text_trimmed = _trim_resume_text(resume_text, sorted_gaps)
        
        # LLMå®Ÿè¡Œã¨ãƒ‘ãƒ¼ã‚¹ï¼ˆæœ€å¤§3å›ãƒªãƒˆãƒ©ã‚¤ï¼‰
        max_retries = 3
        for attempt in range(max_retries):
            try:
                prompt = prompt_template.format(
                    job_text=job_text_trimmed,
                    resume_text=resume_text_trimmed,
                    matched_str=matched_str,
                    gaps_str=gaps_str
                )
                output = llm.invoke(prompt)
                result = parser.parse(output.content)
                improvements = result.improvements
                break
            except Exception as parse_error:
                if attempt == max_retries - 1:
                    # æœ€å¾Œã®è©¦è¡Œã§ã‚‚å¤±æ•—ã—ãŸå ´åˆã¯ä¾‹å¤–ã‚’æŠ•ã’ã‚‹
                    raise parse_error
                # ãƒªãƒˆãƒ©ã‚¤

    except Exception as e:
        print(f"âš ï¸  LLMç”Ÿæˆã«å¤±æ•—ã€fallbackã‚’ä½¿ç”¨: {e}")
        # Fallback: ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ç”Ÿæˆ
        improvements = _fallback_generate(sorted_gaps)

    return improvements


def _trim_job_text(job_text: str, gaps: List[Gap], max_length: int = 800) -> str:
    """
    job_textã‚’å¿…è¦æœ€å°é™ã«ã‚«ãƒƒãƒˆï¼ˆã‚®ãƒ£ãƒƒãƒ—ã«é–¢é€£ã™ã‚‹éƒ¨åˆ†ã‚’å„ªå…ˆï¼‰
    
    Args:
        job_text: æ±‚äººç¥¨ã®ãƒ†ã‚­ã‚¹ãƒˆ
        gaps: ã‚®ãƒ£ãƒƒãƒ—ãƒªã‚¹ãƒˆ
        max_length: æœ€å¤§æ–‡å­—æ•°
        
    Returns:
        str: ã‚«ãƒƒãƒˆå¾Œã®ãƒ†ã‚­ã‚¹ãƒˆ
    """
    if len(job_text) <= max_length:
        return job_text
    
    # ã‚®ãƒ£ãƒƒãƒ—ã«é–¢é€£ã™ã‚‹éƒ¨åˆ†ã‚’æŠ½å‡º
    relevant_parts = []
    for gap in gaps:
        quote = gap.requirement.job_quote
        if quote and quote in job_text:
            # å¼•ç”¨ã®å‰å¾Œ100æ–‡å­—ã‚’å–å¾—
            idx = job_text.find(quote)
            start = max(0, idx - 100)
            end = min(len(job_text), idx + len(quote) + 100)
            relevant_parts.append((start, end))
    
    # é‡è¤‡ã‚’é™¤å»ã—ã¦ã‚½ãƒ¼ãƒˆ
    relevant_parts = sorted(set(relevant_parts))
    
    # é–¢é€£éƒ¨åˆ†ã‚’çµåˆ
    if relevant_parts:
        trimmed = ""
        for start, end in relevant_parts:
            trimmed += job_text[start:end] + "\n\n"
        
        # é•·ã™ãã‚‹å ´åˆã¯ã•ã‚‰ã«ã‚«ãƒƒãƒˆ
        if len(trimmed) > max_length:
            trimmed = trimmed[:max_length] + "..."
        
        return trimmed
    else:
        # é–¢é€£éƒ¨åˆ†ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯å…ˆé ­ã‚’è¿”ã™
        return job_text[:max_length] + "..."


def _trim_resume_text(resume_text: str, gaps: List[Gap], max_length: int = 800) -> str:
    """
    resume_textã‚’å¿…è¦æœ€å°é™ã«ã‚«ãƒƒãƒˆï¼ˆã‚®ãƒ£ãƒƒãƒ—ã«é–¢é€£ã™ã‚‹éƒ¨åˆ†ã‚’å„ªå…ˆï¼‰
    
    Args:
        resume_text: è·å‹™çµŒæ­´æ›¸ã®ãƒ†ã‚­ã‚¹ãƒˆ
        gaps: ã‚®ãƒ£ãƒƒãƒ—ãƒªã‚¹ãƒˆ
        max_length: æœ€å¤§æ–‡å­—æ•°
        
    Returns:
        str: ã‚«ãƒƒãƒˆå¾Œã®ãƒ†ã‚­ã‚¹ãƒˆ
    """
    if len(resume_text) <= max_length:
        return resume_text
    
    # ã‚®ãƒ£ãƒƒãƒ—ã®è¦ä»¶ã«é–¢é€£ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
    keywords = []
    for gap in gaps:
        desc_words = gap.requirement.description.split()
        keywords.extend([w for w in desc_words if len(w) >= 2])
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚€è¡Œã‚’å„ªå…ˆçš„ã«æŠ½å‡º
    lines = resume_text.split('\n')
    relevant_lines = []
    other_lines = []
    
    for line in lines:
        if any(kw.lower() in line.lower() for kw in keywords):
            relevant_lines.append(line)
        else:
            other_lines.append(line)
    
    # é–¢é€£è¡Œã‚’å„ªå…ˆã—ã¦çµåˆ
    trimmed = "\n".join(relevant_lines)
    
    # ã¾ã ä½™è£•ãŒã‚ã‚‹å ´åˆã¯ä»–ã®è¡Œã‚‚è¿½åŠ 
    if len(trimmed) < max_length:
        remaining = max_length - len(trimmed)
        trimmed += "\n" + "\n".join(other_lines)[:remaining]
    
    # é•·ã™ãã‚‹å ´åˆã¯ã‚«ãƒƒãƒˆ
    if len(trimmed) > max_length:
        trimmed = trimmed[:max_length] + "..."
    
    return trimmed


def _prioritize_gaps(gaps: List[Gap], max_count: int = 5) -> List[Gap]:
    """
    ã‚®ãƒ£ãƒƒãƒ—ã‚’Mustå„ªå…ˆã§ã‚½ãƒ¼ãƒˆã€ä¸Šä½Nä»¶ã‚’é¸æŠ

    Args:
        gaps: ã‚®ãƒ£ãƒƒãƒ—ãƒªã‚¹ãƒˆ
        max_count: æœ€å¤§ä»¶æ•°

    Returns:
        List[Gap]: ã‚½ãƒ¼ãƒˆæ¸ˆã¿ã‚®ãƒ£ãƒƒãƒ—ï¼ˆä¸Šä½Nä»¶ï¼‰
    """
    # Mustè¦ä»¶ã‚’å„ªå…ˆï¼ˆcategory, importanceã®é™é †ï¼‰
    sorted_gaps = sorted(
        gaps,
        key=lambda g: (
            0 if g.requirement.category == RequirementType.MUST else 1,
            -g.requirement.importance
        )
    )

    return sorted_gaps[:max_count]


def _fallback_generate(gaps: List[Gap]) -> Improvements:
    """
    Fallback: ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§ç°¡æ˜“çš„ãªæ”¹å–„æ¡ˆã‚’ç”Ÿæˆ

    Args:
        gaps: ã‚®ãƒ£ãƒƒãƒ—ãƒªã‚¹ãƒˆ

    Returns:
        Improvements: æ”¹å–„æ¡ˆ
    """
    resume_edits = []
    action_items = []

    for i, gap in enumerate(gaps[:5]):
        req = gap.requirement
        is_must = req.category == RequirementType.MUST

        # ResumeEditç”Ÿæˆ
        resume_edits.append(ResumeEdit(
            target_gap=req.req_id,
            edit_type="add",
            template=f"ã€{req.description}ã«é–¢ã™ã‚‹çµŒé¨“ã€‘",
            example=f"{req.description}ã«é–¢ã™ã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚„å­¦ç¿’çµŒé¨“ã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚"
        ))

        # ActionItemç”Ÿæˆ
        priority = "A" if is_must else ("B" if i < 2 else "C")
        estimated_impact = "High" if is_must else "Medium"

        action_items.append(ActionItem(
            priority=priority,
            action=f"{req.description}ã«é–¢ã™ã‚‹ã‚¹ã‚­ãƒ«ã‚’ç¿’å¾—ã™ã‚‹",
            rationale=f"æ±‚äººç¥¨ã§{'å¿…é ˆ' if is_must else 'æ­“è¿'}ã¨ã•ã‚Œã¦ã„ã‚‹ãŸã‚",
            estimated_impact=estimated_impact
        ))

    # Overall strategy
    must_gaps = [g for g in gaps if g.requirement.category == RequirementType.MUST]
    if must_gaps:
        strategy = f"ã¾ãšMustè¦ä»¶ã®ä¸è¶³ï¼ˆ{len(must_gaps)}ä»¶ï¼‰ã‚’åŸ‹ã‚ã‚‹ã“ã¨ã‚’æœ€å„ªå…ˆã«ã€å­¦ç¿’ã‚„å®Ÿç¸¾ä½œã‚Šã«å–ã‚Šçµ„ã‚“ã§ãã ã•ã„ã€‚"
    else:
        strategy = "Wantè¦ä»¶ã‚’å¼·åŒ–ã™ã‚‹ã“ã¨ã§ã€ã•ã‚‰ã«é©åˆåº¦ã‚’é«˜ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚"

    return Improvements(
        resume_edits=resume_edits,
        action_items=action_items,
        overall_strategy=strategy
    )


# ==================== ãƒ†ã‚¹ãƒˆç”¨ã‚³ãƒ¼ãƒ‰ ====================
if __name__ == "__main__":
    from models import Requirement, Evidence, RequirementType, ConfidenceLevel

    # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    print("=" * 60)
    print("F4: æ”¹å–„æ¡ˆç”Ÿæˆãƒ†ã‚¹ãƒˆï¼ˆãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨ï¼‰")
    print("=" * 60)

    # ã‚µãƒ³ãƒ—ãƒ«æ±‚äººç¥¨
    sample_job_text = """
ã€æ±‚äººç¥¨ã€‘Webã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢å‹Ÿé›†

â– å¿…é ˆã‚¹ã‚­ãƒ«
ãƒ»Pythoné–‹ç™ºçµŒé¨“3å¹´ä»¥ä¸Š
ãƒ»Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–‹ç™ºã®å®Ÿå‹™çµŒé¨“
ãƒ»Docker/Kubernetesã®å®Ÿå‹™çµŒé¨“

â– æ­“è¿ã‚¹ã‚­ãƒ«
ãƒ»AWSãªã©ã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒã§ã®é–‹ç™ºçµŒé¨“
ãƒ»æ©Ÿæ¢°å­¦ç¿’ãƒ»ãƒ‡ãƒ¼ã‚¿åˆ†æã®çŸ¥è­˜
    """

    # ã‚µãƒ³ãƒ—ãƒ«è·å‹™çµŒæ­´æ›¸
    sample_resume_text = """
ã€è·å‹™çµŒæ­´æ›¸ã€‘

â– è·å‹™çµŒæ­´
2019å¹´ã€œç¾åœ¨ï¼šæ ªå¼ä¼šç¤¾ABC
ãƒ»Pythonã‚’ä½¿ç”¨ã—ãŸWebã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–‹ç™ºã«5å¹´é–“å¾“äº‹
ãƒ»Djangoãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ç”¨ã„ãŸECã‚µã‚¤ãƒˆã®æ§‹ç¯‰
ãƒ»AWS (EC2, S3, RDS) ã‚’æ´»ç”¨ã—ãŸã‚¤ãƒ³ãƒ•ãƒ©æ§‹ç¯‰

â– ã‚¹ã‚­ãƒ«
ãƒ»Pythonï¼ˆ5å¹´ï¼‰ã€JavaScriptï¼ˆ3å¹´ï¼‰
ãƒ»Django, Flask, FastAPI
ãƒ»AWS, Docker, Git
    """

    # ãƒ€ãƒŸãƒ¼è¦ä»¶ï¼ˆF1ã®å‡ºåŠ›ç›¸å½“ï¼‰
    requirements = [
        Requirement(
            req_id="REQ_001",
            category=RequirementType.MUST,
            description="Pythoné–‹ç™ºçµŒé¨“3å¹´ä»¥ä¸Š",
            importance=5,
            job_quote="Pythoné–‹ç™ºçµŒé¨“3å¹´ä»¥ä¸Š",
            weight=1.0
        ),
        Requirement(
            req_id="REQ_002",
            category=RequirementType.MUST,
            description="Docker/Kubernetesã®å®Ÿå‹™çµŒé¨“",
            importance=4,
            job_quote="Docker/Kubernetesã®å®Ÿå‹™çµŒé¨“",
            weight=1.0
        ),
        Requirement(
            req_id="REQ_003",
            category=RequirementType.WANT,
            description="æ©Ÿæ¢°å­¦ç¿’ãƒ»ãƒ‡ãƒ¼ã‚¿åˆ†æã®çŸ¥è­˜",
            importance=3,
            job_quote="æ©Ÿæ¢°å­¦ç¿’ãƒ»ãƒ‡ãƒ¼ã‚¿åˆ†æã®çŸ¥è­˜",
            weight=0.5
        ),
    ]

    # ãƒ€ãƒŸãƒ¼ãƒãƒƒãƒï¼ˆF3ã®å‡ºåŠ›ç›¸å½“ï¼‰
    matched = [
        RequirementWithEvidence(
            requirement=requirements[0],
            evidence=Evidence(
                req_id="REQ_001",
                resume_quotes=["Pythonã‚’ä½¿ç”¨ã—ãŸWebã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–‹ç™ºã«5å¹´é–“å¾“äº‹"],
                confidence=1.0,
                confidence_level=ConfidenceLevel.HIGH,
                reason="5å¹´é–“ã®PythonçµŒé¨“ãŒæ˜è¨˜ã•ã‚Œã¦ã„ã‚‹"
            )
        )
    ]

    # ãƒ€ãƒŸãƒ¼ã‚®ãƒ£ãƒƒãƒ—ï¼ˆF3ã®å‡ºåŠ›ç›¸å½“ï¼‰
    gaps = [
        Gap(
            requirement=requirements[1],
            evidence=Evidence(
                req_id="REQ_002",
                resume_quotes=["Docker"],
                confidence=0.3,
                confidence_level=ConfidenceLevel.LOW,
                reason="Dockerã®è¨˜è¼‰ã¯ã‚ã‚‹ãŒKubernetesã®å®Ÿå‹™çµŒé¨“ãŒä¸æ˜"
            )
        ),
        Gap(
            requirement=requirements[2],
            evidence=Evidence(
                req_id="REQ_003",
                resume_quotes=[],
                confidence=0.0,
                confidence_level=ConfidenceLevel.NONE,
                reason="æ©Ÿæ¢°å­¦ç¿’ãƒ»ãƒ‡ãƒ¼ã‚¿åˆ†æã«é–¢ã™ã‚‹è¨˜è¼‰ãŒãªã„"
            )
        ),
    ]

    try:
        # F4: æ”¹å–„æ¡ˆç”Ÿæˆ
        print("\n[å®Ÿè¡Œ] F4: æ”¹å–„æ¡ˆç”Ÿæˆ")
        improvements = generate_improvements(
            job_text=sample_job_text,
            resume_text=sample_resume_text,
            requirements=requirements,
            matched=matched,
            gaps=gaps,
            options={"max_gaps": 5}
        )

        print(f"\n{'='*60}")
        print("ğŸ“‹ æ”¹å–„æ¡ˆ")
        print(f"{'='*60}")

        print(f"\nã€å…¨ä½“æˆ¦ç•¥ã€‘\n{improvements.overall_strategy}\n")

        # ResumeEdits
        if improvements.resume_edits:
            print(f"\nâœï¸  è·å‹™çµŒæ­´æ›¸ã®ç·¨é›†ãƒ»è¿½è¨˜æ¡ˆï¼ˆ{len(improvements.resume_edits)}ä»¶ï¼‰")
            for i, edit in enumerate(improvements.resume_edits, 1):
                print(f"\n  {i}. å¯¾è±¡: {edit.target_gap} ({edit.edit_type})")
                print(f"     ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ: {edit.template}")
                print(f"     ä¾‹: {edit.example[:100]}...")

        # ActionItems
        if improvements.action_items:
            print(f"\nğŸ¯ è¡Œå‹•è¨ˆç”»ï¼ˆ{len(improvements.action_items)}ä»¶ï¼‰")
            for i, item in enumerate(improvements.action_items, 1):
                print(f"\n  {i}. [å„ªå…ˆåº¦{item.priority}] {item.action}")
                print(f"     æ ¹æ‹ : {item.rationale}")
                print(f"     åŠ¹æœ: {item.estimated_impact}")

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
